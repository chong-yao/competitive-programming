{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/aiolympiadmy/baku-or-pasar/train.jsonl\", \n",
    "    \"train.jsonl\"\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/aiolympiadmy/baku-or-pasar/test.jsonl\", \n",
    "    \"test.jsonl\"\n",
    ")\n",
    "\n",
    "with open(\"train.jsonl\", \"r\") as f:\n",
    "    train = [json.loads(line) for line in f]\n",
    "    X_train_full = [item[\"text\"] for item in train]\n",
    "    y_train_full = [0 if item[\"class\"] == 0 else 1 for item in train]\n",
    "\n",
    "with open(\"test.jsonl\", \"r\") as f:\n",
    "    test = [json.loads(line) for line in f]\n",
    "    X_test = [item[\"text\"] for item in test]\n",
    "    test_ids = [item[\"id\"] for item in test]\n",
    "\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "print(\"Evaluating model performance...\\n\")\n",
    "\n",
    "# Cross-validated F1 score\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train_full, y_train_full, cv=cv, scoring='f1')\n",
    "\n",
    "print(f\"Cross-validated F1 scores: {[round(s, 4) for s in cv_scores]}\")\n",
    "print(f\"Mean F1: {round(cv_scores.mean(), 4)} (±{round(cv_scores.std(), 4)})\")\n",
    "\n",
    "# Validation split evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    test_size=0.2, \n",
    "    stratify=y_train_full,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "val_preds = model.predict(X_val)\n",
    "\n",
    "print(\"\\nValidation set performance:\")\n",
    "print(f\"F1 Score: {round(f1_score(y_val, val_preds), 4)}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, val_preds))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, val_preds, digits=4))\n",
    "\n",
    "# ------------------------\n",
    "# 3. Final Predictions\n",
    "# ------------------------\n",
    "# Retrain on full data\n",
    "print(\"\\nTraining final model on full dataset...\")\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Generate predictions\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Format results\n",
    "answer = [{\"id\": tid, \"class\": int(pred)} for tid, pred in zip(test_ids, test_preds)]\n",
    "\n",
    "print(\"\\nFinal predictions:\")\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# 1. Enhanced Text Preprocessing\n",
    "# ------------------------\n",
    "class MalayTextNormalizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.replacements = {\n",
    "            r'\\bwk\\b': 'week', r'\\bskg\\b': 'sekarang', r'\\bjt\\b': 'juta',\n",
    "            r'\\bbyk\\b': 'banyak', r'\\bgk\\b': 'juga', r'\\btdk\\b': 'tidak',\n",
    "            r'\\bkyk\\b': 'seperti', r'\\bbsr\\b': 'besar', r'\\bblh\\b': 'boleh'\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self._normalize_text(text) for text in X]\n",
    "    \n",
    "    def _normalize_text(self, text):\n",
    "        # Remove emojis\n",
    "        text = emoji.replace_emoji(text, replace=' ')\n",
    "        # Replace internet slang\n",
    "        text = text.lower()\n",
    "        for pattern, replacement in self.replacements.items():\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        # Normalize repeated vowels\n",
    "        text = re.sub(r'([aeiou])\\1{2,}', r'\\1\\1', text)\n",
    "        # Remove non-Malay characters\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Collapse whitespace\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# ------------------------\n",
    "# 2. Download and load data\n",
    "# ------------------------\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/aiolympiadmy/baku-or-pasar/train.jsonl\", \n",
    "    \"train.jsonl\"\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/aiolympiadmy/baku-or-pasar/test.jsonl\", \n",
    "    \"test.jsonl\"\n",
    ")\n",
    "\n",
    "with open(\"train.jsonl\", \"r\") as f:\n",
    "    train = [json.loads(line) for line in f]\n",
    "    X_train = [item[\"text\"] for item in train]\n",
    "    y_train = [0 if item[\"class\"] == 0 else 1 for item in train]\n",
    "\n",
    "with open(\"test.jsonl\", \"r\") as f:\n",
    "    test = [json.loads(line) for line in f]\n",
    "    test_ids = [item[\"id\"] for item in test]\n",
    "\n",
    "# ------------------------\n",
    "# 3. Optimized Feature Engineering\n",
    "# ------------------------\n",
    "pipeline = make_pipeline(\n",
    "    MalayTextNormalizer(),\n",
    "    TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 5)),\n",
    "    LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4. Precision Parameter Tuning\n",
    "# ------------------------\n",
    "param_grid = {\n",
    "    'tfidfvectorizer__max_df': [0.75, 0.8],\n",
    "    'tfidfvectorizer__min_df': [1, 2],\n",
    "    'tfidfvectorizer__sublinear_tf': [True],\n",
    "    'logisticregression__C': np.logspace(-2, 1, 10),\n",
    "    'logisticregression__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best F1: {grid_search.best_score_:.4f}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# ------------------------\n",
    "# 5. Final Predictions\n",
    "# ------------------------\n",
    "# Ensemble predictions using voting\n",
    "test_preds_proba = best_model.predict_proba([item[\"text\"] for item in test])\n",
    "test_preds = (test_preds_proba[:, 1] > 0.43).astype(int)  # Threshold tuning\n",
    "\n",
    "answer = [{\"id\": tid, \"class\": int(pred)} for tid, pred in zip(test_ids, test_preds)]\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# ------------------------\n",
    "# 1. Text Preprocessing\n",
    "# ------------------------\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self._clean_text(text) for text in X]\n",
    "    \n",
    "    def _clean_text(self, text):\n",
    "        # Remove special characters and emojis\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Normalize repeated characters (e.g., jaaa -> jaa)\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "        return text.lower().strip()\n",
    "\n",
    "# ------------------------\n",
    "# 2. Download and load data\n",
    "# ------------------------\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/aiolympiadmy/baku-or-pasar/train.jsonl\", \n",
    "    \"train.jsonl\"\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/aiolympiadmy/baku-or-pasar/test.jsonl\", \n",
    "    \"test.jsonl\"\n",
    ")\n",
    "\n",
    "with open(\"train.jsonl\", \"r\") as f:\n",
    "    train = [json.loads(line) for line in f]\n",
    "    X_train_full = [item[\"text\"] for item in train]\n",
    "    y_train_full = [0 if item[\"class\"] == 0 else 1 for item in train]\n",
    "\n",
    "with open(\"test.jsonl\", \"r\") as f:\n",
    "    test = [json.loads(line) for line in f]\n",
    "    test_ids = [item[\"id\"] for item in test]\n",
    "\n",
    "# ------------------------\n",
    "# 3. Optimized Pipeline\n",
    "# ------------------------\n",
    "pipeline = make_pipeline(\n",
    "    TextPreprocessor(),\n",
    "    TfidfVectorizer(ngram_range=(1, 2)),  # Include bigrams\n",
    "    LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4. Hyperparameter Tuning\n",
    "# ------------------------\n",
    "param_grid = {\n",
    "    'tfidfvectorizer__max_df': [0.85, 0.9],\n",
    "    'tfidfvectorizer__min_df': [2, 3],\n",
    "    'logisticregression__C': [0.5, 1, 2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"\\nBest parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best F1: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 5. Final Model Training\n",
    "# ------------------------\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation with best model\n",
    "cv_scores = cross_val_score(\n",
    "    best_model, \n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "print(\"\\nOptimized model cross-validation:\")\n",
    "print(f\"F1 scores: {[round(s, 4) for s in cv_scores]}\")\n",
    "print(f\"Mean F1: {round(np.mean(cv_scores), 4)} (±{round(np.std(cv_scores), 4)})\")\n",
    "\n",
    "# Train final model\n",
    "best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# ------------------------\n",
    "# 6. Generate Predictions\n",
    "# ------------------------\n",
    "test_preds = best_model.predict([item[\"text\"] for item in test])\n",
    "\n",
    "answer = [{\"id\": tid, \"class\": int(pred)} for tid, pred in zip(test_ids, test_preds)]\n",
    "\n",
    "# Submit answer\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
