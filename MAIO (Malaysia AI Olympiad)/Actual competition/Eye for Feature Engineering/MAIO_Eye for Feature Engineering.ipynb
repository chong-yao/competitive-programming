{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34dd59c-09b9-457a-8a11-6daccfb97ae0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[32m      4\u001b[39m dino = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mhttps://storage.googleapis.com/aiolympiadmy/maio_2025_eye_for_feature_engineering.csv\u001b[39m\u001b[33m\"\u001b[39m, index_col=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "dino = pd.read_csv(\"https://storage.googleapis.com/aiolympiadmy/maio_2025_eye_for_feature_engineering.csv\", index_col=0)\n",
    "X, y = dino[[\"feature1\", \"feature2\"]], dino[\"class\"]\n",
    "def create_new_feature(X):\n",
    "    return X[\"feature1\"]\n",
    "# Create the feature itself\n",
    "X[\"feature3\"] = create_new_feature(X)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "y_pred_logreg = logreg.predict(X)\n",
    "print(\"Logreg precision / recall / f1_score\", \n",
    "    precision_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"), \n",
    "    recall_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
    "    f1_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05900d7f-46e9-4002-be6c-27c6dcab44a5",
   "metadata": {},
   "source": [
    "## Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c6493-1350-466a-8b37-b7e0280a8e12",
   "metadata": {},
   "source": [
    "Above is a peculiar dataset passed through a logistic regression classifier. Notice that the baseline example provided above scores 0 for precision, recall and F1 score. (Google / ask ChatGPT and friends if you're learning of these terms for the first time!)\n",
    "\n",
    "Do what you can to raise the F1 score as much as possible, subject to the following restrictions:\n",
    "\n",
    "- You cannot edit the existing model prediction logic in the Your Submission section:\n",
    "    - except for the cell containing `create_new_feature()` itself\n",
    "    - except for the cell marked for you to import new libraries\n",
    "- You can still add new code cells to this notebooks under the Scratchpad section below. Do all your exploration and testing here. However, code in Your Submission must not depend on code in your Scratchpad in any way. Only code from Your Submission will be run during evaluation.\n",
    "\n",
    "This challenge will be graded via notebook submission only. Scoring as follows:\n",
    "\n",
    "- Up to 10 pts for model performance, F1 score X 10. Partial credit may be granted for incomplete submissions at discretion. So show your work below!\n",
    "- +3 pts if F1 score >= 0.5 and no neural networks are involved. Neural networks here are strictly defined as the use of learnable weights and biases\n",
    "- +2 pts if F1 score >= 0.5 and the `%%timeit` cell reports runtime <= 10 milliseconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5eec5-4647-4e18-96e2-0bf7a85b3c6d",
   "metadata": {},
   "source": [
    "## Your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9a4b1-3ac3-44fc-a9e2-68663bce20c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Usage (with plot):\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m labels = create_new_feature(\u001b[43mdino\u001b[49m, plot=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dino' is not defined"
     ]
    }
   ],
   "source": [
    "# EDIT ME\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def create_new_feature(X, plot=False):\n",
    "    X_array = X[[\"feature1\", \"feature2\"]].values\n",
    "    dbscan = DBSCAN(eps=7, min_samples=3)\n",
    "    labels = dbscan.fit_predict(X_array)\n",
    "    \n",
    "    if plot:  # Only plot when explicitly requested\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(X_array[:, 0], X_array[:, 1], c = labels)\n",
    "        plt.show()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Usage (with plot):\n",
    "labels = create_new_feature(dino, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "# DO NOT EDIT - timing cell\n",
    "create_new_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe6fa9-81a7-4700-aec2-ea12369915aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT - scoring cell\n",
    "X[\"feature3\"] = create_new_feature(X)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "y_pred_logreg = logreg.predict(X)\n",
    "\n",
    "print(\"Logreg precision / recall\", \n",
    "    precision_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"), \n",
    "    recall_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
    "    f1_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
